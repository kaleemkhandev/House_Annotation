{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/gettyimages-81888267-612x612.jpg',\n",
       " 'test/gettyimages-1281554848-612x612.jpg',\n",
       " 'test/front-lawn-of-suburban-house-royalty-free-image-1658177220.jpg',\n",
       " 'test/gettyimages-157168323-612x612.jpg',\n",
       " 'test/gettyimages-200478943-001-612x612.jpg',\n",
       " 'test/istockphoto-157376658-612x612.jpg',\n",
       " 'test/gettyimages-128502214-612x612.jpg',\n",
       " 'test/gettyimages-157649292-612x612.jpg',\n",
       " 'test/johnson-johnson-U6Q6zVDgmSs-unsplash.jpg',\n",
       " 'test/gettyimages-76038132-612x612.jpg',\n",
       " 'test/gettyimages-981616638-612x612.jpg',\n",
       " 'test/gettyimages-1327080125-612x612.jpg',\n",
       " 'test/gettyimages-171246403-612x612.jpg',\n",
       " 'test/wallpaperflare.com_wallpaper.jpg',\n",
       " 'test/phil-hearing-IYfp2Ixe9nM-unsplash.jpg',\n",
       " 'test/gettyimages-184859699-612x612.jpg',\n",
       " 'test/gettyimages-528689816-612x612.jpg',\n",
       " 'test/gettyimages-1354034882-612x612.jpg',\n",
       " 'test/jacques-bopp-Hh18POSx5qk-unsplash.jpg',\n",
       " 'test/gettyimages-168338782-612x612.jpg',\n",
       " 'test/gettyimages-76185214-612x612.jpg',\n",
       " 'test/gettyimages-AA014332-612x612.jpg',\n",
       " 'test/gettyimages-185269607-612x612.jpg',\n",
       " 'test/gettyimages-1167399452-612x612.jpg',\n",
       " 'test/gettyimages-73774401-612x612.jpg',\n",
       " 'test/gettyimages-157441498-612x612.jpg',\n",
       " 'test/gettyimages-175422480-612x612.jpg',\n",
       " 'test/01_Original_Image (1).jpg',\n",
       " 'test/gettyimages-103761765-612x612.jpg',\n",
       " 'test/gettyimages-57224059-612x612.jpg',\n",
       " 'test/gettyimages-200066801-001-612x612.jpg',\n",
       " 'test/istockphoto-1415886888-170667a.jpg',\n",
       " 'test/gettyimages-483773209-612x612.jpg',\n",
       " 'test/gettyimages-469386580-612x612.jpg']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(\"test/*\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(files):\n",
    "    shutil.copy(file,f\"images/{i}.jpg\")\n",
    "    txt = file.split(\"/\")[-1].replace('.jpg','.txt')\n",
    "    shutil.copy(f\"ground_truth/{txt}\",f\"gnd_truths/{i}_gt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/7.jpg: 384x640 2 windows, 1 door, 1 garage, 3.6ms\n",
      "Speed: 1.0ms preprocess, 3.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/0.jpg: 384x640 4 windows, 1 door, 1 garage, 3.2ms\n",
      "Speed: 0.9ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/31.jpg: 384x640 18 windows, 1 door, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/39.jpg: 384x640 12 windows, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/26.jpg: 384x640 7 windows, 1 door, 4.8ms\n",
      "Speed: 1.4ms preprocess, 4.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/29.jpg: 384x640 2 windows, 1 door, 5.0ms\n",
      "Speed: 1.1ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/32.jpg: 384x640 1 window, 4.1ms\n",
      "Speed: 1.0ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/46.jpg: 384x640 5 windows, 1 door, 1 garage, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/41.jpg: 384x640 3 windows, 1 door, 2 garages, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/47.jpg: 384x640 5 windows, 1 door, 3.8ms\n",
      "Speed: 1.4ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/12.jpg: 384x640 11 windows, 1 door, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/23.jpg: 384x640 12 windows, 1 door, 4.9ms\n",
      "Speed: 1.3ms preprocess, 4.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/42.jpg: 384x640 4 windows, 1 door, 1 garage, 5.6ms\n",
      "Speed: 1.1ms preprocess, 5.6ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/1.jpg: 384x640 11 windows, 1 door, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/38.jpg: 384x640 4 windows, 3.7ms\n",
      "Speed: 1.6ms preprocess, 3.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/13.jpg: 384x640 8 windows, 1 door, 1 garage, 4.6ms\n",
      "Speed: 0.9ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/37.jpg: 384x640 3 windows, 1 door, 2 garages, 5.0ms\n",
      "Speed: 2.4ms preprocess, 5.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/11.jpg: 384x640 3 windows, 1 door, 1 garage, 5.0ms\n",
      "Speed: 1.6ms preprocess, 5.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/24.jpg: 384x640 9 windows, 1 door, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/22.jpg: 384x640 7 windows, 1 door, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/51.jpg: 384x640 5 windows, 1 door, 3 garages, 5.2ms\n",
      "Speed: 1.6ms preprocess, 5.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/40.jpg: 384x640 6 windows, 1 door, 1 garage, 4.5ms\n",
      "Speed: 1.3ms preprocess, 4.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/8.jpg: 384x640 1 window, 1 door, 1 garage, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/25.jpg: 384x640 11 windows, 1 door, 1 garage, 3.6ms\n",
      "Speed: 1.3ms preprocess, 3.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/5.jpg: 384x640 8 windows, 2 doors, 1 garage, 3.7ms\n",
      "Speed: 1.2ms preprocess, 3.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/33.jpg: 384x640 10 windows, 3.8ms\n",
      "Speed: 1.1ms preprocess, 3.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/17.jpg: 384x640 6 windows, 1 door, 3.7ms\n",
      "Speed: 1.3ms preprocess, 3.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/19.jpg: 384x640 5 windows, 2 garages, 3.8ms\n",
      "Speed: 1.5ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/45.jpg: 384x640 8 windows, 1 door, 3.8ms\n",
      "Speed: 1.6ms preprocess, 3.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/50.jpg: 384x640 4 windows, 1 door, 2 garages, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/43.jpg: 384x640 6 windows, 1 door, 4.6ms\n",
      "Speed: 0.9ms preprocess, 4.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/28.jpg: 384x640 3 windows, 1 door, 1 garage, 4.1ms\n",
      "Speed: 1.1ms preprocess, 4.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/10.jpg: 384x640 7 windows, 1 door, 1 garage, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/34.jpg: 384x640 2 windows, 2 doors, 3.9ms\n",
      "Speed: 1.9ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/35.jpg: 384x640 3 windows, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/30.jpg: 384x640 6 windows, 2 doors, 4.1ms\n",
      "Speed: 1.3ms preprocess, 4.1ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/44.jpg: 384x640 3 windows, 1 door, 1 garage, 4.3ms\n",
      "Speed: 0.9ms preprocess, 4.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/27.jpg: 384x640 7 windows, 2 doors, 3.9ms\n",
      "Speed: 0.9ms preprocess, 3.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/14.jpg: 384x640 5 windows, 2 doors, 2 garages, 4.5ms\n",
      "Speed: 0.9ms preprocess, 4.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/48.jpg: 384x640 6 windows, 1 door, 1 garage, 4.0ms\n",
      "Speed: 1.8ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/16.jpg: 384x640 6 windows, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/6.jpg: 384x640 5 windows, 1 door, 1 garage, 3.9ms\n",
      "Speed: 1.0ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/2.jpg: 384x640 4 windows, 2 doors, 4.0ms\n",
      "Speed: 0.9ms preprocess, 4.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/49.jpg: 384x640 7 windows, 1 door, 1 garage, 3.7ms\n",
      "Speed: 1.0ms preprocess, 3.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/15.jpg: 384x640 11 windows, 1 door, 4.9ms\n",
      "Speed: 1.3ms preprocess, 4.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/36.jpg: 384x640 5 windows, 1 door, 1 garage, 4.9ms\n",
      "Speed: 1.2ms preprocess, 4.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/4.jpg: 384x640 5 windows, 2 doors, 1 garage, 3.2ms\n",
      "Speed: 1.1ms preprocess, 3.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/9.jpg: 384x640 3 windows, 1 door, 3.4ms\n",
      "Speed: 1.1ms preprocess, 3.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/20.jpg: 384x640 3 windows, 1 door, 2 garages, 3.5ms\n",
      "Speed: 1.0ms preprocess, 3.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/21.jpg: 384x640 4 windows, 1 door, 3.5ms\n",
      "Speed: 1.1ms preprocess, 3.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/3.jpg: 384x640 6 windows, 1 door, 3.8ms\n",
      "Speed: 1.0ms preprocess, 3.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/adlytic/Desktop/usama/SAM/yolov8_data/resized/images/18.jpg: 384x640 1 window, 1 garage, 3.8ms\n",
      "Speed: 1.2ms preprocess, 3.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# 0 = door\n",
    "# 1 = garrage\n",
    "# 2 = window\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('weights/detetor/best_house.pt')  # load a custom model\n",
    "files = os.listdir('yolov8_data/resized/images')\n",
    "# Predict with the model\n",
    "for file in files:\n",
    "    results = model(f\"yolov8_data/resized/images/{file}\")\n",
    "    boxes = results[0].boxes.xywhn.cpu().tolist()\n",
    "    classes = [int(x) for x in results[0].boxes.cls.cpu().tolist()]\n",
    "    confidence = results[0].boxes.conf.cpu().tolist()\n",
    "    lines = []\n",
    "    classes=[2 if x == 0 else 0 if x == 1 else 1 for x in classes]\n",
    "    for i, box in enumerate(boxes):\n",
    "        box.insert(0,confidence[i])\n",
    "        box.insert(0, classes[i])\n",
    "        lines.append(box)\n",
    "    ann = file.split(\".\")[0]\n",
    "    with open(f'yolov8_data/resized/pred/{ann}_pred.txt','w') as f:\n",
    "        for line in lines:\n",
    "            row_str = ' '.join(str(element) for element in line)  # Convert each element to string\n",
    "            f.write(row_str + '\\n')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 1, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs = results[0].boxes.conf.cpu().tolist()\n",
    "boxes = results[0].boxes.xywhn.cpu().tolist()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for i, box in enumerate(boxes):\n",
    "    box.insert(0,confs[i])\n",
    "    box.insert(0, classes[i])\n",
    "    lines.append(box)\n",
    "    break\n",
    "\n",
    "# with open('test.txt','w') as f:\n",
    "#     for line in lines:\n",
    "#         row_str = ' '.join(str(element) for element in line)  # Convert each element to string\n",
    "#         f.write(row_str + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.9790241718292236,\n",
       " 0.25459611415863037,\n",
       " 0.2861822545528412,\n",
       " 0.08900390565395355,\n",
       " 0.14056110382080078]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def calculate_iou(gt_mask, pred_mask):\n",
    "    intersection = np.logical_and(gt_mask, pred_mask)\n",
    "    union = np.logical_or(gt_mask, pred_mask)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou\n",
    "\n",
    "def calculate_miou(gt_masks, pred_masks, num_classes):\n",
    "    miou_sum = 0.0\n",
    "    for class_id in range(num_classes):\n",
    "        gt_class_mask = (gt_masks == class_id).astype(np.uint8)\n",
    "        pred_class_mask = (pred_masks == class_id).astype(np.uint8)\n",
    "        iou = calculate_iou(gt_class_mask, pred_class_mask)\n",
    "        miou_sum += iou\n",
    "    miou = miou_sum / num_classes\n",
    "    return miou\n",
    "\n",
    "# Example usage\n",
    "gt_masks = np.array([   # Ground truth masks (shape: [num_samples, height, width])\n",
    "    [[1, 0, 0], [0, 1, 1], [1, 1, 0]],\n",
    "    [[1, 0, 1], [0, 1, 0], [0, 0, 1]]\n",
    "])\n",
    "\n",
    "pred_masks = np.array([   # Predicted masks (shape: [num_samples, height, width])\n",
    "    [[1, 0, 0], [0, 1, 0], [1, 1, 0]],\n",
    "    [[0, 0, 1], [1, 1, 0], [0, 0, 1]]\n",
    "])\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "miou = calculate_miou(gt_masks, pred_masks, num_classes)\n",
    "print(\"mIoU:\", miou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15911433100700378,\n",
       " 0.5904607772827148,\n",
       " 0.2113124132156372,\n",
       " 0.6883756518363953]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolov8_data/resized/train/images/gettyimages-175422480-612x612_jpg.rf.2aa7461eecbe3226967efd2264d46916.jpg yolov8_data/resized/train/labels/gettyimages-175422480-612x612_jpg.rf.2aa7461eecbe3226967efd2264d46916.txt\n",
      "yolov8_data/resized/images/0.jpg yolov8_data/resized/anns/0_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-171246403-612x612_jpg.rf.3c952fc7d5873e342180440d60a6de50.jpg yolov8_data/resized/train/labels/gettyimages-171246403-612x612_jpg.rf.3c952fc7d5873e342180440d60a6de50.txt\n",
      "yolov8_data/resized/images/1.jpg yolov8_data/resized/anns/1_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-1167399452-612x612_jpg.rf.4cb1e4c26d80b7f969108566dcaabae7.jpg yolov8_data/resized/train/labels/gettyimages-1167399452-612x612_jpg.rf.4cb1e4c26d80b7f969108566dcaabae7.txt\n",
      "yolov8_data/resized/images/2.jpg yolov8_data/resized/anns/2_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-185269607-612x612_jpg.rf.8d0d0294f25483b7b517bb2403ecbb02.jpg yolov8_data/resized/train/labels/gettyimages-185269607-612x612_jpg.rf.8d0d0294f25483b7b517bb2403ecbb02.txt\n",
      "yolov8_data/resized/images/3.jpg yolov8_data/resized/anns/3_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-157441498-612x612_jpg.rf.badb148c6648be717b398520b96442fa.jpg yolov8_data/resized/train/labels/gettyimages-157441498-612x612_jpg.rf.badb148c6648be717b398520b96442fa.txt\n",
      "yolov8_data/resized/images/4.jpg yolov8_data/resized/anns/4_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-73774401-612x612_jpg.rf.17222da78c3a26e4bb878fdc3fe8d97f.jpg yolov8_data/resized/train/labels/gettyimages-73774401-612x612_jpg.rf.17222da78c3a26e4bb878fdc3fe8d97f.txt\n",
      "yolov8_data/resized/images/5.jpg yolov8_data/resized/anns/5_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-AA014332-612x612_jpg.rf.e52eafe715a1a4daaa1f291ad688c12d.jpg yolov8_data/resized/train/labels/gettyimages-AA014332-612x612_jpg.rf.e52eafe715a1a4daaa1f291ad688c12d.txt\n",
      "yolov8_data/resized/images/6.jpg yolov8_data/resized/anns/6_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-469386580-612x612_jpg.rf.7900afb3f13870e6073054c7e48f14cf.jpg yolov8_data/resized/train/labels/gettyimages-469386580-612x612_jpg.rf.7900afb3f13870e6073054c7e48f14cf.txt\n",
      "yolov8_data/resized/images/7.jpg yolov8_data/resized/anns/7_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-184859699-612x612_jpg.rf.371ba26ace113dc2a87863cefbb0f222.jpg yolov8_data/resized/train/labels/gettyimages-184859699-612x612_jpg.rf.371ba26ace113dc2a87863cefbb0f222.txt\n",
      "yolov8_data/resized/images/8.jpg yolov8_data/resized/anns/8_gt.txt\n",
      "yolov8_data/resized/train/images/istockphoto-1415886888-170667a_jpg.rf.cdc6b1ba187862ef731f9ec704859b18.jpg yolov8_data/resized/train/labels/istockphoto-1415886888-170667a_jpg.rf.cdc6b1ba187862ef731f9ec704859b18.txt\n",
      "yolov8_data/resized/images/9.jpg yolov8_data/resized/anns/9_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-81888267-612x612_jpg.rf.d8289322c2942c5578c5bedc4c8446ce.jpg yolov8_data/resized/train/labels/gettyimages-81888267-612x612_jpg.rf.d8289322c2942c5578c5bedc4c8446ce.txt\n",
      "yolov8_data/resized/images/10.jpg yolov8_data/resized/anns/10_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-981616638-612x612_jpg.rf.caea991e6d9178230e464a73f8de520a.jpg yolov8_data/resized/train/labels/gettyimages-981616638-612x612_jpg.rf.caea991e6d9178230e464a73f8de520a.txt\n",
      "yolov8_data/resized/images/11.jpg yolov8_data/resized/anns/11_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-76038132-612x612_jpg.rf.4ed8da3b7f1e16e55beb79b420f33d33.jpg yolov8_data/resized/train/labels/gettyimages-76038132-612x612_jpg.rf.4ed8da3b7f1e16e55beb79b420f33d33.txt\n",
      "yolov8_data/resized/images/12.jpg yolov8_data/resized/anns/12_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-200478943-001-612x612_jpg.rf.d5e31d5d339fd00e4f85358a16299a87.jpg yolov8_data/resized/train/labels/gettyimages-200478943-001-612x612_jpg.rf.d5e31d5d339fd00e4f85358a16299a87.txt\n",
      "yolov8_data/resized/images/13.jpg yolov8_data/resized/anns/13_gt.txt\n",
      "yolov8_data/resized/train/images/wallpaperflare-com_wallpaper_jpg.rf.551a9ea9ec0ddffcb404cda09b1f922d.jpg yolov8_data/resized/train/labels/wallpaperflare-com_wallpaper_jpg.rf.551a9ea9ec0ddffcb404cda09b1f922d.txt\n",
      "yolov8_data/resized/images/14.jpg yolov8_data/resized/anns/14_gt.txt\n",
      "yolov8_data/resized/train/images/jacques-bopp-Hh18POSx5qk-unsplash_jpg.rf.88e168ec2f3c444a216feb98cb409860.jpg yolov8_data/resized/train/labels/jacques-bopp-Hh18POSx5qk-unsplash_jpg.rf.88e168ec2f3c444a216feb98cb409860.txt\n",
      "yolov8_data/resized/images/15.jpg yolov8_data/resized/anns/15_gt.txt\n",
      "yolov8_data/resized/train/images/johnson-johnson-U6Q6zVDgmSs-unsplash_jpg.rf.52437d87f83c6aaccd9a497eac6f9fba.jpg yolov8_data/resized/train/labels/johnson-johnson-U6Q6zVDgmSs-unsplash_jpg.rf.52437d87f83c6aaccd9a497eac6f9fba.txt\n",
      "yolov8_data/resized/images/16.jpg yolov8_data/resized/anns/16_gt.txt\n",
      "yolov8_data/resized/train/images/01_Original_Image-1-_jpg.rf.bb53fcb7b256cfce3adcf7a658868fba.jpg yolov8_data/resized/train/labels/01_Original_Image-1-_jpg.rf.bb53fcb7b256cfce3adcf7a658868fba.txt\n",
      "yolov8_data/resized/images/17.jpg yolov8_data/resized/anns/17_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-1327080125-612x612_jpg.rf.0b4fa6cae5e63fb48dc5364e80c0ec4d.jpg yolov8_data/resized/train/labels/gettyimages-1327080125-612x612_jpg.rf.0b4fa6cae5e63fb48dc5364e80c0ec4d.txt\n",
      "yolov8_data/resized/images/18.jpg yolov8_data/resized/anns/18_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-1281554848-612x612_jpg.rf.49ac696555fde790cfae8eaf78bb489d.jpg yolov8_data/resized/train/labels/gettyimages-1281554848-612x612_jpg.rf.49ac696555fde790cfae8eaf78bb489d.txt\n",
      "yolov8_data/resized/images/19.jpg yolov8_data/resized/anns/19_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-157168323-612x612_jpg.rf.c21ae259ed522ef469d364133590d201.jpg yolov8_data/resized/train/labels/gettyimages-157168323-612x612_jpg.rf.c21ae259ed522ef469d364133590d201.txt\n",
      "yolov8_data/resized/images/20.jpg yolov8_data/resized/anns/20_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-528689816-612x612_jpg.rf.d308bb4ff62cb089b7fab96c385b0c9e.jpg yolov8_data/resized/train/labels/gettyimages-528689816-612x612_jpg.rf.d308bb4ff62cb089b7fab96c385b0c9e.txt\n",
      "yolov8_data/resized/images/21.jpg yolov8_data/resized/anns/21_gt.txt\n",
      "yolov8_data/resized/train/images/front-lawn-of-suburban-house-royalty-free-image-1658177220_jpg.rf.7ab2a889165cd07e8efc22ca36359e04.jpg yolov8_data/resized/train/labels/front-lawn-of-suburban-house-royalty-free-image-1658177220_jpg.rf.7ab2a889165cd07e8efc22ca36359e04.txt\n",
      "yolov8_data/resized/images/22.jpg yolov8_data/resized/anns/22_gt.txt\n",
      "yolov8_data/resized/train/images/istockphoto-157376658-612x612_jpg.rf.96d69a6ccf386ea54d601602ba78aa21.jpg yolov8_data/resized/train/labels/istockphoto-157376658-612x612_jpg.rf.96d69a6ccf386ea54d601602ba78aa21.txt\n",
      "yolov8_data/resized/images/23.jpg yolov8_data/resized/anns/23_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-57224059-612x612_jpg.rf.5ad9c28ad4886924d466347c7d9d9453.jpg yolov8_data/resized/train/labels/gettyimages-57224059-612x612_jpg.rf.5ad9c28ad4886924d466347c7d9d9453.txt\n",
      "yolov8_data/resized/images/24.jpg yolov8_data/resized/anns/24_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-157649292-612x612_jpg.rf.779d8442220d7af71b28b1439a7d7bd3.jpg yolov8_data/resized/train/labels/gettyimages-157649292-612x612_jpg.rf.779d8442220d7af71b28b1439a7d7bd3.txt\n",
      "yolov8_data/resized/images/25.jpg yolov8_data/resized/anns/25_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-128502214-612x612_jpg.rf.ef6585939df1264ec235ae7c43bb43a1.jpg yolov8_data/resized/train/labels/gettyimages-128502214-612x612_jpg.rf.ef6585939df1264ec235ae7c43bb43a1.txt\n",
      "yolov8_data/resized/images/26.jpg yolov8_data/resized/anns/26_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-1354034882-612x612_jpg.rf.fe226a90cb9d52a7fc9cda8e39128286.jpg yolov8_data/resized/train/labels/gettyimages-1354034882-612x612_jpg.rf.fe226a90cb9d52a7fc9cda8e39128286.txt\n",
      "yolov8_data/resized/images/27.jpg yolov8_data/resized/anns/27_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-483773209-612x612_jpg.rf.e8e50aff21c9194bc650523ea86e9592.jpg yolov8_data/resized/train/labels/gettyimages-483773209-612x612_jpg.rf.e8e50aff21c9194bc650523ea86e9592.txt\n",
      "yolov8_data/resized/images/28.jpg yolov8_data/resized/anns/28_gt.txt\n",
      "yolov8_data/resized/train/images/phil-hearing-IYfp2Ixe9nM-unsplash_jpg.rf.fd136b2aa822aa1e05635d5a3bbe1f0f.jpg yolov8_data/resized/train/labels/phil-hearing-IYfp2Ixe9nM-unsplash_jpg.rf.fd136b2aa822aa1e05635d5a3bbe1f0f.txt\n",
      "yolov8_data/resized/images/29.jpg yolov8_data/resized/anns/29_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-168338782-612x612_jpg.rf.014187bd1e3c9b1a3ee7b95096080eb8.jpg yolov8_data/resized/train/labels/gettyimages-168338782-612x612_jpg.rf.014187bd1e3c9b1a3ee7b95096080eb8.txt\n",
      "yolov8_data/resized/images/30.jpg yolov8_data/resized/anns/30_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-200066801-001-612x612_jpg.rf.7dfbf3cc37461677b14c24a5c3311fd2.jpg yolov8_data/resized/train/labels/gettyimages-200066801-001-612x612_jpg.rf.7dfbf3cc37461677b14c24a5c3311fd2.txt\n",
      "yolov8_data/resized/images/31.jpg yolov8_data/resized/anns/31_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-76185214-612x612_jpg.rf.408252daf547954861cd6f00bf08cb26.jpg yolov8_data/resized/train/labels/gettyimages-76185214-612x612_jpg.rf.408252daf547954861cd6f00bf08cb26.txt\n",
      "yolov8_data/resized/images/32.jpg yolov8_data/resized/anns/32_gt.txt\n",
      "yolov8_data/resized/train/images/gettyimages-103761765-612x612_jpg.rf.52598d3f2052d381b5de24ea1a7d47b2.jpg yolov8_data/resized/train/labels/gettyimages-103761765-612x612_jpg.rf.52598d3f2052d381b5de24ea1a7d47b2.txt\n",
      "yolov8_data/resized/images/33.jpg yolov8_data/resized/anns/33_gt.txt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "images = os.listdir('yolov8_data/resized/train/images/')\n",
    "for i,img in enumerate(images):\n",
    "    src_img = f\"yolov8_data/resized/train/images/{img}\"\n",
    "    dest_img = f\"yolov8_data/resized/images/{i}.jpg\"\n",
    "    ann = img.replace('.jpg','.txt')\n",
    "    src_ann = f\"yolov8_data/resized/train/labels/{ann}\"\n",
    "    dest_ann = f\"yolov8_data/resized/anns/{i}_gt.txt\"\n",
    "    print(src_img,src_ann)\n",
    "    print(dest_img,dest_ann)\n",
    "    shutil.copy(src_img,dest_img)\n",
    "    shutil.copy(src_ann,dest_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('sam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3167a1a47bb718270b22315d30414836ea27e0007b88877a37676ffb27f0d77b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
